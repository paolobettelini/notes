\documentclass[preview]{standalone}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stellar}
\usepackage{definitions}

\begin{document}

\id{matrices-systems-of-linear-equations}
\genpage

\section{Elementary row operations}

\includesnpt{linearalgebra-elementary-row-operations}

\plain{We can construct matrices such when multiplied an elementary row addition operation is performed.}

\begin{snippetdefinition}{elementary-lambda-matrix-definition}{Elementary \(\lambda\) matrix}
    The \emph{elementary matrix} \(E_{i,j}(\lambda)\) is the \(n\times n\) \matrix defined as
    \[
        E_{i,j}(\lambda) = \identmatrix{n} + \lambda e_{i,j}
    \]
    where \(e_{i,k}\) is the \matrix with all entries zero expect for a \(1\) at position \((i,j)\).
\end{snippetdefinition}

\begin{snippetproposition}{elementary-matrix-row-operation}{}
    Let \(A\) be an \(n\times m\) \matrix. Then, the product \(E_{i,j}(\lambda)A\) is the \matrix obtained by
    adding \(\lambda\) times the \(j\)-th row of \(A\) to the \(i\)-th row, which is the
    \snippetref[linearalgebra-elementary-row-operations][elementary row addition operation].
\end{snippetproposition}

\begin{snippetproof}{elementary-matrix-row-operation-proof}{elementary-matrix-row-operation}{}
    Let \(A\) have rows rows \(a_1, a_2, \dots, a_n\), written as:
    \[
        A =
        \begin{bmatrix}
        a_1 \\ a_2 \\ \vdots \\ a_n
        \end{bmatrix}.
    \]
    Ccompute the matrix product \(E_{i,j}(\lambda) A\).
    Since \(E_{i,j}(\lambda) = I_n + \lambda e_{i,j}\), we expand:
    \[
        E_{i,j}(\lambda) A = (I_n + \lambda e_{i,j}) A = I_n A + \lambda e_{i,j} A.
    \]
    Since \(I_n A = A\), it remains to compute \(e_{i,j} A\).
    By the definition of \(e_{i,j}\), this matrix has only one nonzero row: it picks row \(j\) of \(A\)
    and places it in row \(i\), with all other rows being zero. Thus, we get:
    \[
        e_{i,j} A =
        \begin{bmatrix}
        0 \\ \vdots \\ 0 \\ a_j \\ 0 \\ \vdots \\ 0
        \end{bmatrix},
    \]
    where \(a_j\) appears in row \(i\), and all other rows are zero.
    Multiplying by \(\lambda\) gives:
    \[
        \lambda e_{i,j} A =
        \begin{bmatrix}
        0 \\ \vdots \\ 0 \\ \lambda a_j \\ 0 \\ \vdots \\ 0
        \end{bmatrix}.
    \]
    Adding this to \(A\), we see that only row \(i\) is modified:
    \[
        E_{i,j}(\lambda) A =
        \begin{bmatrix}
        a_1 \\ \vdots \\ a_{i-1} \\ a_i + \lambda a_j \\ a_{i+1} \\ \vdots \\ a_n
        \end{bmatrix}.
    \]
    Thus, row \(i\) is updated as \(a_i + \lambda a_j\), while all other rows remain unchanged.
\end{snippetproof}

\section{Systems of linear equations}

\begin{snippetproposition}{trivial-system-of-linear-equations-solution}{Trivial system of linear equations}
    Let \(a,b \in \realnumbers\). Then, the solution to
    \[
        ax = b
    \]
    is given by
    \[
        \begin{cases}
            x = \frac{b}{a} & a \neq 0 \\
            x \in \emptyset & a = 0 \land b \neq 0 \\
            x \in \realnumbers & a = 0 \land b = 0
        \end{cases}
    \]
\end{snippetproposition}

\begin{snippet}{systems-of-linear-equations}
    A system of linear equations
    \begin{align*}
        a_{1, 1}x + a_{1, 2}y + \cdots + a_{1, m}z &= b_1 \\
        a_{2, 1}x + a_{2, 2}y + \cdots + a_{2, m}z &= b_2 \\
        \cdots \\
        a_{n, 1}x + a_{n, 2}y + \cdots + a_{n, m}z &= b_n
    \end{align*}

    Can be represented by a matrix multiplication \(M\vec{x}=\vec{d}\)

    \[
        \begin{bmatrix} 
            a_{1, 1} && a_{1, 2} && \cdots && a_{1, m} \\
            a_{2, 1} && a_{2, 2} && \cdots && a_{2, m} \\
            \vdots && \vdots && \ddots && \vdots \\
            a_{n, 1} && b_{n, 2} && \cdots && a_{n, m}
        \end{bmatrix}
        \begin{bmatrix}
            x_1 \\ y_2 \\ \vdots \\ y_n
        \end{bmatrix}
        =
        \begin{bmatrix}
            b_1 \\ b_2 \\ \vdots \\ b_n
        \end{bmatrix}
    \]

    The geometrical interpretation is to find the vector \(\vec{x}\)
    such that when the matrix \(M\) is applied to it, the resulting vector is \(\vec{d}\).

    We may represent the whole system just by
    \[
        \begin{bmatrix} 
            a_{1, 1} && a_{1, 2} && \cdots && a_{1, m} && b_1 \\
            a_{2, 1} && a_{2, 2} && \cdots && a_{2, m} && b_2 \\
            \vdots && \vdots && \vdots && \ddots && \vdots \\
            a_{n, 1} && b_{n, 2} && \cdots && a_{n, m} && b_n
        \end{bmatrix}
    \]
\end{snippet}

\subsection{Using elementary row operations}

\begin{snippet}{linearalgebra-expl1}
    Applying \snippetref[linearalgebra-elementary-row-operations][elementary row operations]
    does not change the solution of the linear system.
\end{snippet}

\includesnpt{linearalgebra-lin-sys-sol-amount}

\begin{snippet}{linearalgebra-expl2}
    By applying these operations, our goal is to make the system matrix
    look like the following:
    \[
        \begin{bmatrix} 
            1 && 0 && 0 && e_1 \\
            0 && 1 && 0 && e_2 \\
            0 && 0 && 1 && e_3
        \end{bmatrix}
    \]
    which is the implicit solution
    \(x=e_1\), \(y=e_2\) and \(z=e_3\).
    If this is possible, then this is the only solution to our system.

    \vspace{.25cm}

    If it is possible to create a row whose elements are all \(0\)s,
    then there are infinitely many solutions, because
    there are infinitely many solutions for the equation
    \(0x_1+0x_2+\cdots+0x_n = 0\).

    \vspace{.25cm}

    If it is possible to create a whose elements elements
    are all \(0\)s expect for the last one there are zero solutions,
    because there are zero solutions for the equation
    \(0x_1+0x_2+\cdots+0x_n = a\) with \(a \neq 0\).
\end{snippet}

\subsubsection{Examples}

\includesnpt{linearalgebra-matrix-linear-system-1-sol-example-1}
\includesnpt{linearalgebra-matrix-linear-system-inf-sol-example-1}
\includesnpt{linearalgebra-matrix-linear-system-0-sol-example-1}

\section{Cramer's rule}

\begin{snippettheorem}{cramer-rule-theorem}{Cramer's rule}
    Consider a system of \(n\) equations and unknowns
    \[
        A\vec{x}=\vec{b}
    \]
    The solution is given by
    \[
        \vec{x}_i = \frac{\det(A_i)}{\det(A)}
    \]
    where \(A_i\) is formed by replacing the \(i\)-th column
    of \(A\) by \(\vec{b}\).
\end{snippettheorem}

\end{document}