\documentclass[preview]{standalone}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stellar}
\usepackage{definitions}

\begin{document}

\id{implicit-function-theorem-exercises}
\genpage

\section{Exercises}

\begin{snippetexercise}{implicit-function-theorem-ex1}{}
    Show that the equation
    \[ xe^y - ye^x - 1 = 0 \]
    implicitly defines a unique function \(y = \varphi(x)\) in a \neighborhood of \((1,0)\).
    Determine \(\varphi'(1)\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex1-sol}{}
    Let \(F(x,y) = xe^y - ye^x - 1\).
    First, we verify that the point \((1,0)\) satisfies the equation:
    \[
        F(1,0) = 1 \cdot e^0 - 0 \cdot e^1 - 1 = 1 - 1 = 0
    \]
    The partial derivatives of \(F\) are:
    \begin{align*}
        F_x(x,y) &= e^y - ye^x \\
        F_y(x,y) &= xe^y - e^x
    \end{align*}
    These are continuous functions, so \(F \in \mathcal{C}^1\). We verify the condition on the derivative with respect to \(y\) at the point \((1,0)\):
    \[
        F_y(1,0) = 1 \cdot e^0 - e^1 = 1 - e \neq 0
    \]
    Since \(F(1,0) = 0\) and \(F_y(1,0) \neq 0\), by the Implicit Function Theorem, the equation defines a unique function \(y = \varphi(x)\) in a \neighborhood of \((1,0)\).
    
    To determine \(\varphi'(1)\), we compute:
    \[
        \varphi'(1) = -\frac{F_x(1,0)}{F_y(1,0)}
    \]
    We have \(F_x(1,0) = e^0 - 0 = 1\). Thus:
    \[
        \varphi'(1) = -\frac{1}{1-e} = \frac{1}{e-1}
    \]
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex2}{}
    Show that the equation
    \[ \sqrt[3]{x^2 - y}-2x + y = 0 \]
    implicitly defines a unique function \(y = \varphi(x)\) in a \neighborhood of \((2,3)\).
    Determine \(\varphi'(2)\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex2-sol}{}
    Let \(F(x,y) = \sqrt[3]{x^2 - y} - 2x + y\).
    First, we check that the point \((2,3)\) lies on the curve defined by \(F(x,y) = 0\):
    \[
        F(2,3) = \sqrt[3]{4 - 3} - 4 + 3 = 1 - 1 = 0
    \]
    Next, we compute the partial derivatives. Recall that \(\sqrt[3]{u} = u^{1/3}\).
    \begin{align*}
        F_x(x,y) &= \frac{1}{3}(x^2 - y)^{-2/3}(2x) - 2 = \frac{2x}{3\sqrt[3]{(x^2-y)^2}} - 2 \\
        F_y(x,y) &= \frac{1}{3}(x^2 - y)^{-2/3}(-1) + 1 = 1 - \frac{1}{3\sqrt[3]{(x^2-y)^2}}
    \end{align*}
    We evaluate the partial derivative with respect to \(y\) at the point \((2,3)\):
    \[
        F_y(2,3) = 1 - \frac{1}{3\sqrt[3]{(4-3)^2}} = 1 - \frac{1}{3} = \frac{2}{3}
    \]
    Since \(F_y(2,3) \neq 0\) and \(F\) is \(C^1\) in a \neighborhood of \((2,3)\), the Implicit Function Theorem guarantees the existence of a unique function \(y = \varphi(x)\) defined near \(x=2\).
    
    Finally, we compute \(\varphi'(2)\) using the ratio of the partial derivatives:
    \[
        \varphi'(2) = - \frac{F_x(2,3)}{F_y(2,3)}
    \]
    Evaluating \(F_x\) at \((2,3)\):
    \[
        F_x(2,3) = \frac{2(2)}{3\sqrt[3]{1}} - 2 = \frac{4}{3} - 2 = -\frac{2}{3}
    \]
    Substituting these values gives:
    \[
        \varphi'(2) = - \frac{-2/3}{2/3} = 1
    \]
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex3}{}
    Show that the equation
    \[ x^3 - x\sqrt{y} + x + y = 0 \]
    implicitly defines a unique function \(y = \varphi(x)\) in a \neighborhood of \((-1,1)\).
    Determine \[
        \lim_{x\to -1} \frac{\varphi(x) + 1 + 2x}{{(x+1)}^2}
    \]
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex3-sol}{}
    Let \(f(x,y) = x^3 - x\sqrt{y} + x + y\).
    We have \(f(-1,1) = 0\)
    and \[
        f_y(x,y) = -\frac{x}{2\sqrt{y}} + 1
    \]
    which is continuous in a \neighborhood of \((-1,1)\)
    and \(f_y(-1,1) = \frac32 \neq 0\). Thus, there exists a unique \function
    \(y = \varphi(x)\) near such a point.
    We will now compute \(\varphi'\). We have
    \begin{align*}
        \left[f(x,\varphi(x))\right]'
        &= [x^3 - x\sqrt{\varphi(x)} + \varphi(x) + x]' \\
        &= 3x^2 - \sqrt{\varphi(x)} - \frac{x\varphi'(x)}{2\sqrt{\varphi(x)}} + \varphi'(x) + 1 = 0 \\
        \varphi'(x) &= \frac{-1-3x^2 + \sqrt{\varphi(x)}}{1-\frac{x}{2\sqrt{\varphi(x)}}} \\
        &= -\frac{f_x(x, \varphi(x))}{f_y(x,\varphi(x))}
    \end{align*}
    For the limit we have
    \begin{align*}
        \lim_{x\to -1} \frac{\varphi'(x) + 2}{2(x+1)}
        &\overset{H}{=} \frac{\varphi'(-1) + 1}{2} = \frac00
    \end{align*}
    We need \(\varphi''(-1)\) to do a Taylor expansion.
    \begin{align*}
        \left\{\left[f(x,\varphi(x))\right]'\right\}'
        &= \left\{3x^2 - \sqrt{\varphi(x)} - \frac{x\varphi'(x)}{2\sqrt{\varphi(x)}} + \varphi'(x) + 1\right\}' \\
        \varphi''(x) \left(- \frac{x}{2 \varphi(x)} + 1\right) &=
        -6x + \frac{\varphi'(x)}{2\sqrt{\varphi(x)}} + \frac{1}{2}
        \frac{\varphi'(x)}{\sqrt{\varphi(x)}} + \frac{1}{4} \frac{x [\varphi'(x)]^2}{\sqrt{\varphi(x)}\varphi(x)} \\
        \varphi''(-1) &= 2
    \end{align*}
    We now have \(\varphi(x) = 1 + \varphi'(-1)(x + 1) + \littleO(x+1)\). Then,
    \begin{align*}
        \lim_{x\to -1} \frac{\varphi''(x)}{2} = 1
    \end{align*}
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex4}{}
    Show that the equation
    \[ x^3 + xy^2 - 2y^3 = 0 \]
    implicitly defines a unique function \(y = \varphi(x)\) in a \neighborhood of \((1,1)\).
    Determine the equation of the line tangent to the graph of \(\varphi\) at \(x=1\).
    Determine \(\varphi''(1)\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex4-sol}{}
    Let \(F(x,y) = x^3 + xy^2 - 2y^3\). (Note: assuming a sign correction so that \(F(1,1) = 0\)).
    We verify the point \((1,1)\):
    \[ F(1,1) = 1 + 1 - 2 = 0 \]
    The partial derivatives are:
    \begin{align*}
        F_x(x,y) &= 3x^2 + y^2 \\
        F_y(x,y) &= 2xy - 6y^2
    \end{align*}
    Evaluating at \((1,1)\):
    \[ F_y(1,1) = 2(1)(1) - 6(1)^2 = -4 \neq 0 \]
    Since \(F_y(1,1) \neq 0\), the Implicit Function Theorem guarantees a unique function \(y=\varphi(x)\) near \((1,1)\).
    
    \paragraph{First Derivative and Tangent Line}
    We compute the derivative \(\varphi'(1)\):
    \[
        \varphi'(1) = -\frac{F_x(1,1)}{F_y(1,1)} = -\frac{3(1)^2 + (1)^2}{-4} = -\frac{4}{-4} = 1
    \]
    The equation of the tangent line at \(x=1\) is:
    \[
        y - \varphi(1) = \varphi'(1)(x - 1) \implies y - 1 = 1(x - 1) \implies y = x
    \]

    \paragraph{Second Derivative}
    To find \(\varphi''(1)\), we implicitly differentiate the equation \(3x^2 + y^2 + 2xyy' - 6y^2y' = 0\) with respect to \(x\):
    \[
        6x + 2yy' + (2y + 2xy')y' + 2xy'' - (12y(y')^2 + 6y^2y'') = 0
    \]
    Substitute \(x=1, y=1, y'=1\):
    \begin{align*}
        6(1) + 2(1)(1) + [2(1) + 2(1)(1)](1) + 2(1)y'' - [12(1)(1)^2 + 6(1)^2y''] &= 0 \\
        6 + 2 + 4 + 2y'' - 12 - 6y'' &= 0 \\
        0 - 4y'' &= 0 \\
        y''(1) &= 0
    \end{align*}
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex5}{}
    Show that the equation
    \[ e^{xy} - e^{-2y}\cos(x) - 1=0 \]
    implicitly defines a unique function \(y = \varphi(x) \in \mathcal{C}^1\) in a \neighborhood of
    \(x_0 = \pi/2\).
    Determine \(\varphi'(\pi/2)\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex5-sol}{}
    Let \(F(x,y) = e^{xy} - e^{-2y}\cos(x) - 1\).
    We must have \(F(x_0, y) = e^{\frac{\pi y}{2}}-1 = 0\)
    and thus \(y=0\). Hence the point is \((\pi/2, 0)\).
    We have the derivatives
    \begin{align*}
        \frac{\partial F}{\partial x} &= ye^{xy} + e^{-2y}\sin(x) \\
        \frac{\partial F}{\partial y} &= xe^{xy} + 2x^{-2y}\cos(x)
    \end{align*}
    At the point we have \(F_y(\pi/2, 0) = \pi/2 \neq 0\) meaning that
    there exists an implicit function. We finally have
    \begin{align*}
        \varphi'\left(\frac{\pi}{2}\right) &=
        -\frac{
            \varphi\left(\frac{\pi}{2}\right) e^{\varphi\left(\frac{\pi}{2}\right)\frac{\pi}{2}}
            + e^{-2\varphi\left(\frac{\pi}{2}\right)}\sin\left(\frac{\pi}{2}\right)
        }{
            \frac{\pi}{2} e^{\varphi\left(\frac{\pi}{2}\right)\frac{\pi}{2}}
            + 2e^{-2\varphi\left(\frac{\pi}{2}\right)}\cos\left(\frac{\pi}{2}\right)
        } = -\frac{2}{\pi}
    \end{align*}
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex6}{}
    Show that the equation
    \[ \sinh(z-1) - e^x + e^y + xz - y = 0 \]
    implicitly defines a unique function \(z = \varphi(x,y)\) in a \neighborhood of \((0,0,1)\).
    Determine the nature of the point \((0,0)\) for \(\varphi\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex6-sol}{}
    Let \(F(x,y,z) = \sinh(z-1) - e^x + e^y + xz - y\).
    First, we verify the point \(P_0 = (0,0,1)\):
    \[
        F(0,0,1) = \sinh(0) - e^0 + e^0 + 0 - 0 = 0 - 1 + 1 = 0
    \]
    We compute the partial derivatives:
    \begin{align*}
        F_x(x,y,z) &= -e^x + z \\
        F_y(x,y,z) &= e^y - 1 \\
        F_z(x,y,z) &= \cosh(z-1) + x
    \end{align*}
    Evaluating at \(P_0\):
    \[
        F_z(0,0,1) = \cosh(0) + 0 = 1 \neq 0
    \]
    By the Implicit Function Theorem, since \(F \in \mathcal{C}^\infty\) and \(F_z(P_0) \neq 0\), the equation implicitly defines a unique function \(z = \varphi(x,y)\) in a \neighborhood of \((0,0,1)\).

    To determine the nature of the point \((0,0)\), we first find the critical points by computing the gradient of \(\varphi\).
    \begin{align*}
        \varphi_x(0,0) &= -\frac{F_x(0,0,1)}{F_z(0,0,1)} = -\frac{-1 + 1}{1} = 0 \\
        \varphi_y(0,0) &= -\frac{F_y(0,0,1)}{F_z(0,0,1)} = -\frac{1 - 1}{1} = 0
    \end{align*}
    Since \(\nabla \varphi(0,0) = (0,0)\), the origin is a critical point. We must now examine the Hessian matrix of \(\varphi\).
    Differentiating the identity \(F_x + F_z \varphi_x = 0\) with respect to \(x\) (and using \(\varphi_x=0\) at the critical point):
    \[
        F_{xx} + F_z \varphi_{xx} = 0 \implies \varphi_{xx}(0,0) = -\frac{F_{xx}(P_0)}{F_z(P_0)}
    \]
    Similarly for \(y\) and the mixed derivative:
    \[
        \varphi_{yy}(0,0) = -\frac{F_{yy}(P_0)}{F_z(P_0)}, \quad \varphi_{xy}(0,0) = -\frac{F_{xy}(P_0)}{F_z(P_0)}
    \]
    Computing the second derivatives of \(F\) at \(P_0\):
    \begin{align*}
        F_{xx} &= -e^x \implies F_{xx}(P_0) = -1 \\
        F_{yy} &= e^y \implies F_{yy}(P_0) = 1 \\
        F_{xy} &= 0 \implies F_{xy}(P_0) = 0
    \end{align*}
    Substituting these values (recall \(F_z(P_0)=1\)):
    \[
        \varphi_{xx}(0,0) = -\frac{-1}{1} = 1, \quad
        \varphi_{yy}(0,0) = -\frac{1}{1} = -1, \quad
        \varphi_{xy}(0,0) = 0
    \]
    The Hessian matrix is:
    \[
        H_\varphi(0,0) = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}
    \]
    Since \(\det(H_\varphi) = -1 < 0\), the point \((0,0)\) is a \textbf{saddle point}.
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex7}{}
    Show that the equation
    \[ x^2 + 2x + e^y + y - z^3 = 0 \]
    implicitly defines a unique function \(y = \varphi(x,z)\) in a \neighborhood of \((-1,0,0)\).
    Determine the equation of the plane tangent to the graph of \(\varphi\) at \((-1,0,0)\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex7-sol}{}
    Let \(F(x,y,z) = x^2 + 2x + e^y + y - z^3\).
    We have \(F(-1,0,0) = 0\) and \(f_y = e^y + 1\)
    meaning \(f_y(-1,0,0) = 2 \neq 0\). Hence there exists a unique function
    \(y = \varphi(x,z)\).
    We also have \(\varphi(-1,0) = 0\) and \(f(x,0,z) > 0\).
    The tangent plane has equation \(y = \varphi(-1,0) + \gradient \varphi(-1,0) \cdot (x + 1, z)\).
    We need \(\varphi_x(-1,0)\) and \(\varphi_z(-1,0)\).
    We know that \(F(x, \varphi(x,z), z) = 0\) and thus
    \[
        \frac{\partial}{\partial x} [F(x,\varphi(x,z), z)] = 0
    \]
    From this we get \(\varphi_x(-1,0) = 0\) and \(\varphi_x(-1,0) = 0\).
    Thus, \((0-1)\) is a critical point for \(\varphi\) and the tangent plane is
    \(y=0\).
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex8}{}
    Verify that \((0,0,0)\) is a critical point for the function \(z = z(x,y,u)\) implicitly
    determined by the equation
    \[
        x^2 + xu^2 + y^2 + e^{xu} - z + y^2e^z = 0
    \]
    Determine the nature of this point.
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex8-sol}{}
    Let \(F(x,y,u,z) = x^2 + xu^2 + y^2 + e^{xu} - z + y^2e^z\).
    We are looking for a function \(z = z(x,y,u)\). First, we determine the value of \(z\) at the origin \((x,y,u) = (0,0,0)\).
    Substituting these values into the equation:
    \[
        0 + 0 + 0 + e^0 - z + 0 = 0 \implies 1 - z = 0 \implies z = 1
    \]
    Thus, the point in \(\realnumbers^4\) is \(P_0 = (0,0,0,1)\).
    We compute the partial derivatives of \(F\) with respect to the domain variables \(x, y, u\) and the dependent variable \(z\):
    \begin{align*}
        F_x &= 2x + u^2 + ue^{xu} \\
        F_y &= 2y + 2ye^z \\
        F_u &= 2xu + xe^{xu} \\
        F_z &= -1 + y^2e^z
    \end{align*}
    Evaluating these at \(P_0 = (0,0,0,1)\):
    \begin{align*}
        F_x(P_0) &= 0 + 0 + 0 = 0 \\
        F_y(P_0) &= 0 + 0 = 0 \\
        F_u(P_0) &= 0 + 0 = 0 \\
        F_z(P_0) &= -1 + 0 = -1 \neq 0
    \end{align*}
    By the Implicit Function Theorem, \(z\) is defined in a \neighborhood of \((0,0,0)\).
    The gradient of \(z\) is given by:
    \[
        \nabla z(0,0,0) = -\frac{1}{F_z(P_0)} \begin{pmatrix} F_x(P_0) \\ F_y(P_0) \\ F_u(P_0) \end{pmatrix} = -\frac{1}{-1} \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} = \mathbf{0}
    \]
    Since the gradient is zero, \((0,0,0)\) is indeed a critical point.

    To determine the nature of the point, we compute the Hessian matrix of \(z\).
    Since \(\nabla z = \mathbf{0}\) at this point, the second derivatives satisfy the simplified relation:
    \[
        z_{\alpha \beta} = -\frac{F_{\alpha \beta}}{F_z}
    \]
    where \(\alpha, \beta \in \{x, y, u\}\). Given \(F_z(P_0) = -1\), we have \(z_{\alpha \beta} = F_{\alpha \beta}(P_0)\).
    We compute the second order partials of \(F\) at \(P_0\):
    \begin{align*}
        F_{xx} &= 2 + u^2e^{xu} \implies F_{xx}(P_0) = 2 \\
        F_{yy} &= 2 + 2e^z \implies F_{yy}(P_0) = 2 + 2e \\
        F_{uu} &= 2x + x^2e^{xu} \implies F_{uu}(P_0) = 0 \\
        F_{xy} &= 0 \implies F_{xy}(P_0) = 0 \\
        F_{xu} &= 2u + e^{xu} + xue^{xu} \implies F_{xu}(P_0) = 1 \\
        F_{yu} &= 0 \implies F_{yu}(P_0) = 0
    \end{align*}
    The Hessian matrix \(H_z(0,0,0)\) is:
    \[
        H_z = \begin{pmatrix}
            2 & 0 & 1 \\
            0 & 2(1+e) & 0 \\
            1 & 0 & 0
        \end{pmatrix}
    \]
    We analyze the eigenvalues. The matrix is block diagonal. One eigenvalue is \(\lambda_1 = 2(1+e) > 0\).
    The remaining block is \(M = \begin{pmatrix} 2 & 1 \\ 1 & 0 \end{pmatrix}\).
    The determinant of \(M\) is \(2(0) - 1(1) = -1\). Since the determinant is negative, \(M\) has one positive and one negative eigenvalue.
    Consequently, \(H_z\) has mixed signs of eigenvalues (indefinite).
    Thus, \((0,0,0)\) is a \textbf{saddle point}.
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex9}{}
    Show that the equation
    \[ xy^2 + y + \sin(xy) + 3(e^x -1) = 0 \]
    implicitly defines a function \(y = y(x)\) in a \neighborhood of \((0,0)\).
    Determine
    \[
        \lim_{x\to 0} \frac{y(x) + 3x}{x}
    \]
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex9-sol}{}
    Let \(F(x,y) = xy^2 + y + \sin(xy) + 3(e^x - 1)\).
    We first verify that the point \((0,0)\) satisfies the equation:
    \[
        F(0,0) = 0 \cdot 0 + 0 + \sin(0) + 3(e^0 - 1) = 0
    \]
    We compute the partial derivatives:
    \begin{align*}
        F_x(x,y) &= y^2 + y\cos(xy) + 3e^x \\
        F_y(x,y) &= 2xy + 1 + x\cos(xy)
    \end{align*}
    We evaluate the partial derivative with respect to \(y\) at \((0,0)\):
    \[
        F_y(0,0) = 0 + 1 + 0 = 1 \neq 0
    \]
    Since \(F \in \mathcal{C}^\infty\) and \(F_y(0,0) \neq 0\), the Implicit Function Theorem ensures the existence of a unique function \(y = y(x)\) defined in a \neighborhood of \(x=0\) such that \(y(0)=0\).

    To compute the limit, we need the first derivative \(y'(0)\).
    \[
        y'(0) = -\frac{F_x(0,0)}{F_y(0,0)}
    \]
    Evaluating \(F_x\) at \((0,0)\):
    \[
        F_x(0,0) = 0 + 0 + 3e^0 = 3
    \]
    Thus,
    \[
        y'(0) = -\frac{3}{1} = -3
    \]
    Now we compute the limit using L'HÃ´pital's rule (since \(y(0)=0\), the form is \(0/0\)):
    \[
        \lim_{x\to 0} \frac{y(x) + 3x}{x} \overset{H}{=} \lim_{x\to 0} \frac{y'(x) + 3}{1} = y'(0) + 3
    \]
    Substituting \(y'(0) = -3\):
    \[
        \lim_{x\to 0} \frac{y(x) + 3x}{x} = -3 + 3 = 0
    \]
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex10}{}
    Consider the \function
    \[
        F(x,y,z) = x^2e^z + y^2 + z = 0
    \]
    \begin{enumerate}
        \item Show that the equation \(F=0\) implicitly defines a function
        \(z = z(x,y)\) in a \neighborhood of \((0,0,0)\);
        \item determine the nature of the point \((0,0)\) for the \function \(z\);
        \item determine whether \((0,0)\) is an absolute maximum;
        \item show that the maximal domain for \(z\) is \(\realnumbers^2\);
        \item compute
        \[\lim_{(x,y) \fromto \infty} z(x,y)\]
    \end{enumerate}
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex10-sol}{}
    Let \(F(x,y,z) = x^2e^z + y^2 + z\).
    \begin{enumerate}
        \item \emph{Existence:}
        First, verify the point \((0,0,0)\):
        \[ F(0,0,0) = 0 \cdot 1 + 0 + 0 = 0 \]
        The partial derivatives are:
        \[
            F_x = 2xe^z, \quad F_y = 2y, \quad F_z = x^2e^z + 1
        \]
        At the origin:
        \[
            F_z(0,0,0) = 0 \cdot 1 + 1 = 1 \neq 0
        \]
        Since \(F \in \mathcal{C}^\infty\) and \(F_z \neq 0\), the Implicit Function Theorem guarantees a unique function \(z = z(x,y)\) in a \neighborhood of \((0,0)\).

        \item \emph{Nature of the point:}
        We compute the gradient of \(z\) at \((0,0)\):
        \[
            z_x(0,0) = -\frac{F_x(0,0,0)}{F_z(0,0,0)} = -\frac{0}{1} = 0, \quad
            z_y(0,0) = -\frac{F_y(0,0,0)}{F_z(0,0,0)} = -\frac{0}{1} = 0
        \]
        Thus, \((0,0)\) is a critical point. We analyze the Hessian.
        Differentiating \(F_x + F_z z_x = 0\) with respect to \(x\) (and evaluating at the critical point where \(z_x=0\)):
        \[
            F_{xx} + F_z z_{xx} = 0 \implies z_{xx} = -\frac{F_{xx}}{F_z}
        \]
        Similarly for \(y\) and mixed terms.
        Evaluating second derivatives of \(F\) at \((0,0,0)\):
        \begin{align*}
            F_{xx} &= 2e^z \implies F_{xx}(0,0,0) = 2 \\
            F_{yy} &= 2 \implies F_{yy}(0,0,0) = 2 \\
            F_{xy} &= 0
        \end{align*}
        Thus:
        \[
            z_{xx}(0,0) = -2, \quad z_{yy}(0,0) = -2, \quad z_{xy}(0,0) = 0
        \]
        The Hessian is definite negative, so \((0,0)\) is a \textbf{local maximum}.

        \item \emph{Absolute Maximum:}
        From the defining equation, we can write:
        \[
            z = -x^2e^z - y^2
        \]
        Since \(x^2 \ge 0\), \(e^z > 0\) and \(y^2 \ge 0\), the right hand side is always \(\le 0\).
        Therefore, \(z(x,y) \le 0\) for all \((x,y) \in \text{Dom}(z)\).
        Since \(z(0,0) = 0\), the origin is the \textbf{absolute maximum}.

        \item \emph{Maximal Domain:}
        Fix arbitrary \((x,y) \in \realnumbers^2\). Let \(h(t) = x^2e^t + t\).
        We want to solve \(h(z) = -y^2\).
        Note that \(h'(t) = x^2e^t + 1 > 0\) for all \(t\), so \(h\) is strictly increasing and injective.
        Furthermore, \(\lim_{t \to -\infty} h(t) = -\infty\) and \(\lim_{t \to +\infty} h(t) = +\infty\).
        By the Intermediate Value Theorem, for any value \(-y^2\), there exists a unique \(z\) satisfying the equation.
        Thus, the domain is \(\realnumbers^2\).

        \item \emph{Limit at infinity:}
        We have \(z = -y^2 - x^2e^z\).
        Since \(x^2e^z \ge 0\), we have \(z \le -y^2\).
        If \(|y| \to \infty\), clearly \(z \to -\infty\).
        If \(y\) is bounded and \(|x| \to \infty\): Suppose \(z\) is bounded below by \(K\). Then \(e^z \ge e^K > 0\).
        Then \(z = -y^2 - x^2e^z \le -y^2 - x^2e^K \to -\infty\), a contradiction.
        Thus, in all directions:
        \[
            \lim_{(x,y) \to \infty} z(x,y) = -\infty
        \]
    \end{enumerate}
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex11}{}
    Show that the equation
    \[ e^z + (x^2 - y^2)z - (1+xy)e^{\sin(x^2 + y^2)} = 0 \]
    implicitly defines a function \(z = z(x,y)\) in a \neighborhood of \((0,0,0)\)
    and determine the nature of the point \((0,0)\) for \(z\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex11-sol}{}
    Let \(F(x,y,z) = e^z + (x^2 - y^2)z - (1+xy)e^{\sin(x^2 + y^2)}\).
    First, verify the point \(P_0 = (0,0,0)\):
    \[
        F(0,0,0) = e^0 + (0)0 - (1+0)e^0 = 1 - 1 = 0
    \]
    Compute the partial derivatives:
    \begin{align*}
        F_x &= 2xz - \left[y e^{\sin(x^2+y^2)} + (1+xy)e^{\sin(x^2+y^2)} \cos(x^2+y^2) \cdot 2x\right] \\
        F_y &= -2yz - \left[x e^{\sin(x^2+y^2)} + (1+xy)e^{\sin(x^2+y^2)} \cos(x^2+y^2) \cdot 2y\right] \\
        F_z &= e^z + (x^2 - y^2)
    \end{align*}
    At \(P_0(0,0,0)\):
    \[
        F_z(0,0,0) = e^0 + 0 = 1 \neq 0
    \]
    Since \(F \in \mathcal{C}^\infty\) and \(F_z(0,0,0) \neq 0\), the Implicit Function Theorem ensures the existence of a unique function \(z = z(x,y)\) in a \neighborhood of \((0,0)\).

    To determine the nature of the point \((0,0)\), we compute the gradient of \(z\) at the origin.
    Recall that \(\nabla z(0,0) = -\frac{1}{F_z(0,0,0)} \nabla_{(x,y)} F(0,0,0)\).
    Evaluating the partials at the origin:
    \begin{align*}
        F_x(0,0,0) &= 0 - [0 + (1) \cdot 1 \cdot 1 \cdot 0] = 0 \\
        F_y(0,0,0) &= 0 - [0 + (1) \cdot 1 \cdot 1 \cdot 0] = 0
    \end{align*}
    Thus, \(\nabla z(0,0) = (0,0)\), so \((0,0)\) is a critical point.

    We now compute the Hessian matrix \(H_z(0,0)\).
    Since \(\nabla z(0,0) = 0\) and \(F_z(0,0,0) = 1\), we have the simplified formula for second derivatives:
    \[
        z_{xx} = -F_{xx}, \quad z_{xy} = -F_{xy}, \quad z_{yy} = -F_{yy}
    \]
    evaluated at \((0,0,0)\).
    Let's compute the second derivatives of \(F\) at the origin.
    For \(F_{xx}\):
    The term \(2xz\) has derivative \(2z + 2xz_x\). At \((0,0,0)\) this is 0.
    The term \(-(1+xy)e^{\sin(x^2+y^2)}\) behaves like \(-e^{\sin(x^2)}\) near \(y=0\).
    Using Taylor expansion for the second term:
    \(-(1+xy)e^{\sin(x^2+y^2)} \approx -(1+xy)(1 + (x^2+y^2) + \dots) \approx -1 - x^2 - y^2 - xy\).
    Thus \(F(x,y,0) \approx 1 + 0 - (1 + x^2 + y^2 + xy) = -x^2 - y^2 - xy\).
    Alternatively, computing strictly:
    \begin{align*}
        F_{xx}(0,0,0) &= - \left. \frac{\partial}{\partial x} \left( y e^{\sin} + 2x(1+xy)e^{\sin}\cos \right) \right|_{(0,0,0)} \\
        &= - [ 0 + 2(1)(1)(1) ] = -2
    \end{align*}
    Similarly for \(F_{yy}\):
    \begin{align*}
        F_{yy}(0,0,0) &= - [ 0 + 2(1)(1)(1) ] = -2
    \end{align*}
    For the mixed derivative \(F_{xy}\):
    \begin{align*}
        F_{xy}(0,0,0) &= - \left. \frac{\partial}{\partial x} \left( x e^{\sin} + 2y(1+xy)e^{\sin}\cos \right) \right|_{(0,0,0)} \\
        &= - [ 1 \cdot e^0 + 0 ] = -1
    \end{align*}
    So the Hessian of \(z\) is:
    \[
        H_z(0,0) = \begin{pmatrix} -F_{xx} & -F_{xy} \\ -F_{xy} & -F_{yy} \end{pmatrix}
        = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix}
    \]
    The determinant is \(2(2) - 1(1) = 3 > 0\) and the trace is \(4 > 0\).
    Since the determinant is positive and the trace is positive (or leading principal minor \(2 > 0\)), the matrix is positive definite.
    Therefore, \((0,0)\) is a \textbf{local minimum}.
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex12}{}
    Given the system
    \[
        \begin{cases}
            x + \ln y + 5z - 10 = 0\\
            2x + y^2 + 3z^3 - 25 = 0
        \end{cases}
    \]
    determine which pair of variables can be explicable with respect to the other
    in a \neighborhood of \((0,1,2)\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex12-sol}{}
    Let \(F(x,y,z) = (F_1, F_2)\) where:
    \[
        \begin{cases}
            F_1(x,y,z) = x + \ln y + 5z - 10 \\
            F_2(x,y,z) = 2x + y^2 + 3z^3 - 25
        \end{cases}
    \]
    First, we verify the point \(P = (0,1,2)\):
    \[
        \begin{cases}
            0 + 0 + 10 - 10 = 0 \\
            0 + 1 + 3(8) - 25 = 25 - 25 = 0
        \end{cases}
    \]
    We compute the Jacobian matrix of the system:
    \[
        J_F(x,y,z) = \begin{pmatrix}
            \frac{\partial F_1}{\partial x} & \frac{\partial F_1}{\partial y} & \frac{\partial F_1}{\partial z} \\[0.5em]
            \frac{\partial F_2}{\partial x} & \frac{\partial F_2}{\partial y} & \frac{\partial F_2}{\partial z}
        \end{pmatrix} = \begin{pmatrix}
            1 & \frac{1}{y} & 5 \\
            2 & 2y & 9z^2
        \end{pmatrix}
    \]
    Evaluating at \(P(0,1,2)\):
    \[
        J_F(0,1,2) = \begin{pmatrix}
            1 & 1 & 5 \\
            2 & 2 & 36
        \end{pmatrix}
    \]
    To determine which variables can be expressed as functions of the remaining variable, we check the determinants of the \(2 \times 2\) submatrices corresponding to the pairs of dependent variables.
    \begin{enumerate}
        \item \emph{Pair \((x,y)\) as functions of \(z\):}
        \[
            \det \frac{\partial(F_1, F_2)}{\partial(x, y)} = \det \begin{pmatrix} 1 & 1 \\ 2 & 2 \end{pmatrix} = 2 - 2 = 0
        \]
        Since the determinant is zero, we \textbf{cannot} explicitate \(x\) and \(y\) as functions of \(z\) in a \neighborhood of \(P\).

        \item \emph{Pair \((x,z)\) as functions of \(y\):}
        \[
            \det \frac{\partial(F_1, F_2)}{\partial(x, z)} = \det \begin{pmatrix} 1 & 5 \\ 2 & 36 \end{pmatrix} = 36 - 10 = 26 \neq 0
        \]
        Since the determinant is non-zero, we \textbf{can} explicitate \(x\) and \(z\) as functions of \(y\).

        \item \emph{Pair \((y,z)\) as functions of \(x\):}
        \[
            \det \frac{\partial(F_1, F_2)}{\partial(y, z)} = \det \begin{pmatrix} 1 & 5 \\ 2 & 36 \end{pmatrix} = 36 - 10 = 26 \neq 0
        \]
        Since the determinant is non-zero, we \textbf{can} explicitate \(y\) and \(z\) as functions of \(x\).
    \end{enumerate}
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex13}{}
    Let \(F \colon \realnumbers^4 \fromto \realnumbers^2\) defined by
    \[
        F(x,y,s,t) = \begin{pmatrix}
            (y + 3)s - \arctan(s + t) + 2x \\
            \sin(s + t) + 3y - x(t+3)
        \end{pmatrix}
    \]
    Show that \(F = 0\) implicitly defines \(s=s(x,y)\) and \(t=t(x,y)\)
    in a \neighborhood of \((0,0,0,0)\). Determine
    \[
        \frac{\partial s}{\partial y}(0,0)
    \]
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex13-sol}{}
Let \(F = (F_1, F_2) \colon \realnumbers^4 \fromto \realnumbers^2\).
    Compute \(\jacobian F(x, y, s, t)\):
    \[
        \jacobian F(x, y, s, t) = \begin{pmatrix}
            2 & s & y + 3 - \frac{1}{1 + (s+t)^2} & -\frac{1}{1 + (s+t)^2} \\[0.5em]
            -(t + 3) & 3 & \cos(s + t) & \cos(s + t) - x
        \end{pmatrix}
    \]
    At the origin:
    \[
        \jacobian F(0, 0, 0, 0) = \begin{pmatrix}
            2 & 0 & 2 & -1 \\
            -3 & 3 & 1 & 1
        \end{pmatrix}
    \]
    We can thus choose arbitrarily two variables as \function[functions] of the other two,
    for example \(s = s(x, y)\) and \(t = t(x, y)\).
    Compute the differential at \((0, 0)\):
    \[
        \text{d}\varphi(x_0) = -F_y(x_0, y_0)^{-1} \circ F_x(x_0, y_0)
    \]
    Since \(F \in \continuityclass^\infty(\realnumbers^4)\), we have \(\varphi \in \continuityclass^\infty\)
    in a \neighborhood of \((0, 0)\).
    \[
        \jacobian_{(x,y)} F(0, 0, 0, 0) = \begin{pmatrix}
            2 & 0 \\
            -3 & 3
        \end{pmatrix}, \quad
        \jacobian_{(s,t)} F(0, 0, 0, 0) = \begin{pmatrix}
            2 & -1 \\
            1 & 1
        \end{pmatrix}
    \]
    And the inverse is given by
    \[
        \jacobian_{(s,t)} F(0, 0, 0, 0)^{-1} = \frac{1}{3} \begin{pmatrix}
            1 & 1 \\
            -1 & 2
        \end{pmatrix}
    \]
    We thus have the differential
    \[
        \text{d}\varphi(0, 0) = -\frac{1}{3} \begin{pmatrix}
            1 & 1 \\
            -1 & 2
        \end{pmatrix}
        \begin{pmatrix}
            2 & 0 \\
            -3 & 3
        \end{pmatrix}
        = \begin{pmatrix}
            1/3 & -1 \\
            1/3 & -2
        \end{pmatrix}
    \]
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex14}{}
    Determine for which \(\lambda \in \realnumbers\) the \function
    \[
        f(x,y) = (x + \lambda y, y - (\lambda + 1)x^2)
    \]
    is a diffeomorphism of \(\realnumbers^2\) on \(\realnumbers^2\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex14-sol}{}
    The Jacobian is given by
    \[
        \jacobian_f(x,y) = \begin{pmatrix}
            1 & \lambda \\ -2(\lambda + 1)x & 1
        \end{pmatrix}
    \]
    Hence the determinant is \(\det \jacobian_f(x,y) = 1 + 2\lambda(\lambda + 1)x\).
    We must have \(\lambda = 0\) or \(\lambda = -1\).
    \begin{enumerate}
        \item if \(\lambda = 0\), \(f(x,y) = (x, y-x^2)\). The inverse is
        \((u,v) \fromto (u, v + u^2)\), smooth and defined on all \(\realnumbers^n2\);
        \item if \(\lambda = -1\), \(f(x,y) = (x-y,y)\). The inverse is
        \((u,v)\fromto (u + v, v)\), smooth and global.
    \end{enumerate}
    Hence, \(f\) is such a diffeomorphism for \(\lambda \in \{0,-1\}\).
\end{snippetsolution}

\begin{snippetexercise}{implicit-function-theorem-ex15}{}
    Let \(F(x, y) = -xe^y + 2y - 1\).
    Show that in a \neighborhood of \((0, \frac{1}{2})\), the solutions of
    \(F(x, y) = 0\) implicitly define a \function \(y = y(x)\).
    Then find the MacLaurin expansion to second order of \(y = y(x)\) at \(x = 0\).
\end{snippetexercise}

\begin{snippetsolution}{implicit-function-theorem-ex15-sol}{}
    Note that the problem is well-posed since \(F(0, \frac{1}{2}) = 0\).
    The condition guaranteeing existence of this \function
    is that \(F_y \neq 0\).
    We have \(F_y = -xe^y + 2\) and \(F_y(0, \frac{1}{2}) = 2 \neq 0\).
    Thus, by the implicit \function theorem, there exists a unique \function \(y = y(x)\)
    such that \(F(x, y(x)) \equiv 0\).
    For the MacLaurin expansion, we have
    \(y(0) = \frac{1}{2}\). Computing the derivative:
    \begin{align*}
        \frac{d}{dx} \left[F(x, y(x))\right]
        &= -e^y - xe^y y' + 2y' = 0
    \end{align*}
    In particular, for \(x = 0\), we have \(-e^{y(0)} - 0 + 2y'(0) = 0\),
    thus \(y'(0) = \frac{e^{1/2}}{2}\).
    To find the next term, differentiate again:
    \begin{align*}
        \frac{d^2}{dx^2}\left[F(x, y(x))\right] = -e^y y' - e^y y' - x(\cdots) + 2y'' = 0
    \end{align*}
    From which we get \(0 = -2e^{y(0)} y'(0) + 2y''(0)\)
    and thus \(y''(0) = \frac{e}{2}\).
    Therefore
    \[
        y(x) = \frac{1}{2} + \frac{1}{2}e^{1/2}x + \frac{1}{4}ex^2 + o(x^2)
    \]
\end{snippetsolution}

\end{document}